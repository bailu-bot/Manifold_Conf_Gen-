{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d803decc-768c-40e3-82ba-aa342a48a205",
   "metadata": {},
   "source": [
    "**老师图 = 基于分子表示得到的概率图 $Q^\\*$**，**学生图 = 基于坐标 $Y$ 得到的概率图 $Q(Y)$**，用**交叉熵 CE(Q\\*, Q(Y))** 做监督，只更新 $Y$（不加物理约束）。\n",
    "\n",
    "下面给出一份**PyTorch 伪代码**（可直接改成可运行代码）。\n",
    "\n",
    "---\n",
    "\n",
    "# 学习模型与可学习参数\n",
    "\n",
    "* **输入**\n",
    "\n",
    "  * 分子表示得到的两两“距离”或相似度矩阵 $D_{\\text{rep}}$（或你已有的 P 矩阵也行）。\n",
    "  * 可选的拓扑掩码 `mask_pairs`（如只监督 hop≤3 的成对关系）。\n",
    "* **核函数**（与 UMAP 类似）\n",
    "\n",
    "  $$\n",
    "  Q_{ij}(\\cdot)=\\frac{1}{1+a\\,d_{ij}^{2b}},\\quad a>0,b>0\n",
    "  $$\n",
    "* **老师图**\n",
    "\n",
    "  $$\n",
    "  Q^\\*=\\;Q(D_{\\text{rep}})\\quad\\text{（把分子表示的距离喂进同一核函数得到概率）}\n",
    "  $$\n",
    "\n",
    "  （若你已有用 smooth-k/fuzzy-union 得到的 $P$，也可以直接把 $Q^\\*=P$。）\n",
    "* **学生图**\n",
    "\n",
    "  $$\n",
    "  Q(Y)=Q\\!\\big(\\,d_{ij}(Y)=\\|y_i-y_j\\|_2\\,\\big)\n",
    "  $$\n",
    "* **目标函数（监督 CE，仅更新 $Y$**）\n",
    "\n",
    "  $$\n",
    "  \\mathcal{L}=\\mathrm{CE}(Q^\\*,Q(Y))\n",
    "  =-\\sum_{i\\neq j}\\big(Q^\\*_{ij}\\log Q_{ij}(Y)+(1-Q^\\*_{ij})\\log(1-Q_{ij}(Y))\\big)\n",
    "  $$\n",
    "* **可学习参数**\n",
    "\n",
    "  * 必选：$Y\\in\\mathbb{R}^{N\\times 3}$（作为 `nn.Parameter`）。\n",
    "  * 可选（保持简单可先固定）：全局 $a,b$；或每行带宽 $\\sigma_i$（进阶）。\n",
    "\n",
    "---\n",
    "\n",
    "# PyTorch 伪代码（不含物理约束）\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------\n",
    "# 0) 准备与实用函数\n",
    "# ---------------------------\n",
    "def center_and_rescale_torch(Y, target_rms=1.0, eps=1e-8):\n",
    "    # 去中心 + 统一尺度（刚体不变 & 稳定优化）\n",
    "    Yc = Y - Y.mean(dim=0, keepdim=True)\n",
    "    rms = torch.sqrt((Yc**2).mean())\n",
    "    scale = target_rms / (rms + eps)\n",
    "    return Yc * scale\n",
    "\n",
    "def Q_from_dist(D, a, b, eps=1e-12):\n",
    "    # 输入任意距离矩阵 D (N,N)；输出概率矩阵 Q in (0,1)\n",
    "    Q = 1.0 / (1.0 + a * (D.clamp_min(eps) ** (2.0 * b)))\n",
    "    Q = Q.clamp(1e-12, 1.0 - 1e-12)\n",
    "    return Q\n",
    "\n",
    "def pairwise_dist_from_Y(Y, eps=1e-12):\n",
    "    # 使用 torch.cdist 计算两两欧氏距离\n",
    "    D = torch.cdist(Y, Y, p=2)\n",
    "    return D.clamp_min(eps)\n",
    "\n",
    "def ce_loss(Q_star, Q_pred, mask=None):\n",
    "    # 交叉熵（成对），可选 mask（如去掉对角、或只监督 hop<=3）\n",
    "    if mask is not None:\n",
    "        Qs = Q_star[mask]\n",
    "        Qp = Q_pred[mask]\n",
    "    else:\n",
    "        Qs = Q_star\n",
    "        Qp = Q_pred\n",
    "    return -(Qs * torch.log(Qp) + (1 - Qs) * torch.log(1 - Qp)).mean()\n",
    "\n",
    "# （可选）把 min_dist 转成 a,b；简单起见可先固定 a,b\n",
    "def find_ab_from_min_dist(min_dist=0.5, spread=3.0, device=\"cpu\"):\n",
    "    # 简单网格近似；项目里可预先离线求好常数\n",
    "    xs = torch.linspace(0, spread, 256, device=device)\n",
    "    target = torch.where(xs <= min_dist, torch.ones_like(xs), torch.exp(-(xs - min_dist)))\n",
    "    best = (torch.tensor(1.0, device=device), torch.tensor(1.0, device=device), 1e9)\n",
    "    for a_ in torch.linspace(0.5, 3.0, 26, device=device):\n",
    "        for b_ in torch.linspace(0.3, 1.6, 27, device=device):\n",
    "            pred = 1.0 / (1.0 + a_ * (xs ** (2.0 * b_)))\n",
    "            err = torch.mean((pred - target) ** 2).item()\n",
    "            if err < best[2]:\n",
    "                best = (a_, b_, err)\n",
    "    return float(best[0]), float(best[1])\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 构造老师图 Q_star\n",
    "# ---------------------------\n",
    "def build_teacher_Q_from_rep(D_rep, a, b, mask_pairs=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    D_rep: 由分子表示得到的两两距离/不相似度 (N,N), torch.Tensor\n",
    "           若你手头是“相似度 S”，可先转 D_rep = f(S) 再用本函数。\n",
    "    a,b  : 核函数参数（可固定）\n",
    "    mask_pairs: bool mask (N,N)（如只监督 hop<=3，且去对角）\n",
    "    \"\"\"\n",
    "    Q_star = Q_from_dist(D_rep.to(device), a, b)\n",
    "    # 对角不监督\n",
    "    N = Q_star.size(0)\n",
    "    eye = torch.eye(N, dtype=torch.bool, device=device)\n",
    "    base_mask = ~eye\n",
    "    if mask_pairs is not None:\n",
    "        base_mask = base_mask & mask_pairs.to(device)\n",
    "    return Q_star, base_mask\n",
    "\n",
    "# ---------------------------\n",
    "# 2) 训练主循环：只学 Y\n",
    "# ---------------------------\n",
    "def fit_Y_by_supervised_CE(D_rep,\n",
    "                           N_atoms,\n",
    "                           a=1.6, b=0.8,         # 或使用 find_ab_from_min_dist() 求\n",
    "                           mask_pairs=None,       # 例如 (hop<=3)\n",
    "                           lr=1e-2, epochs=1000,\n",
    "                           device=\"cpu\",\n",
    "                           max_step=0.2):\n",
    "    \"\"\"\n",
    "    返回学到的 Y (N,3)\n",
    "    \"\"\"\n",
    "    # 老师图\n",
    "    Q_star, mask = build_teacher_Q_from_rep(D_rep, a, b, mask_pairs, device=device)\n",
    "\n",
    "    # 初始化 Y（可用随机 / PCA / 你的初始化）\n",
    "    Y = nn.Parameter(torch.randn(N_atoms, 3, device=device) * 0.1)\n",
    "    opt = torch.optim.Adam([Y], lr=lr)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        # 刚体规范化（可放在更新后；此处放前/后都可）\n",
    "        with torch.no_grad():\n",
    "            Y.data = center_and_rescale_torch(Y.data, target_rms=1.0)\n",
    "\n",
    "        # 前向：Q(Y)\n",
    "        D_Y = pairwise_dist_from_Y(Y)\n",
    "        Q_Y = Q_from_dist(D_Y, a, b)\n",
    "\n",
    "        # CE 损失（只更新 Y）\n",
    "        loss = ce_loss(Q_star, Q_Y, mask=mask)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # （可选）梯度或位移裁剪，避免过大步导致数值抖动\n",
    "        with torch.no_grad():\n",
    "            # 基于梯度构造本步位移并裁剪每原子步长\n",
    "            step = -lr * Y.grad\n",
    "            # 逐原子 trust-region\n",
    "            step_norm = torch.norm(step, dim=1, keepdim=True) + 1e-12\n",
    "            step = step * torch.minimum(torch.ones_like(step_norm),\n",
    "                                        torch.tensor(max_step, device=device) / step_norm)\n",
    "            Y.data += step\n",
    "\n",
    "        if (t % 50) == 0:\n",
    "            print(f\"[{t:04d}] CE_sup={loss.item():.6f}\")\n",
    "\n",
    "    # 结束前做一次规范化\n",
    "    with torch.no_grad():\n",
    "        Y.data = center_and_rescale_torch(Y.data, target_rms=1.0)\n",
    "    return Y.detach()\n",
    "\n",
    "# ---------------------------\n",
    "# 3) 用法示例\n",
    "# ---------------------------\n",
    "# 假设你已经有 N、和表示得到的 D_rep (N,N)：\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# a, b = find_ab_from_min_dist(min_dist=0.5, device=device)  # 或直接给定 a,b\n",
    "# Y_hat = fit_Y_by_supervised_CE(D_rep=torch.tensor(D_rep, dtype=torch.float32, device=device),\n",
    "#                                N_atoms=D_rep.shape[0],\n",
    "#                                a=a, b=b,\n",
    "#                                mask_pairs=torch.tensor(hop<=3),  # 可选；无则传 None\n",
    "#                                lr=0.01, epochs=1000, device=device)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 说明与小贴士\n",
    "\n",
    "* **为什么这样做有优势？**\n",
    "  仅用 CE 对齐图：\n",
    "\n",
    "  1. 对平移/旋转天然不敏感（只看距离），训练稳；\n",
    "  2. “吸引 + 排斥”两种信号同时存在，防塌缩；\n",
    "  3. 若用同一核函数监督**全矩阵**且 CE→0，则两套距离矩阵一致 ⇒ $Y$ 与老师构象一致（刚体/镜像自由度除外）。\n",
    "\n",
    "* **老师图怎么来？**\n",
    "  上面使用 `Q_from_dist(D_rep, a, b)`；如果你已有 UMAP 风格的 $P$（smooth-k + fuzzy union），直接把 `Q_star = P` 也是可以的（目标只是一个 \\[0,1] 概率图）。\n",
    "\n",
    "* **可选扩展（保持“只学 Y”的前提下）**\n",
    "\n",
    "  * 固定 $a,b$ 够用；若想更贴合当前尺度，可每隔 30 轮用当前正对距离的 60% 分位数**微调 min\\_dist**，并重新估 $a,b$。\n",
    "  * 如果只监督 hop≤3，远程自由度较多；但这一版你明确“先不加物理”，完全 OK。\n",
    "\n",
    "把上面的伪代码稍作变量替换（把你的 `D1` 或表示距离矩阵塞给 `D_rep`）即可跑起来。需要我帮你把它**融入你现有脚本**（保留你函数名/记录/可视化）的话，直接把变量名和初始化部分贴我一份就行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b84c4e-3d39-41c0-b9b2-ded35af68d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
