{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7619344f-71d2-436a-89d3-a5773e6fa924",
   "metadata": {},
   "source": [
    "# 基于 UMAP–GNN 概率图对齐的分子三维构象生成\n",
    "\n",
    "**关键词**：UMAP 核、行自适应核、GNN、概率图对齐、交叉熵、摊销推理、非参数微调\n",
    "\n",
    "---\n",
    "\n",
    "## 摘要\n",
    "\n",
    "我们提出一种基于**概率图对齐**的分子构象生成方法。用真实构象 $Y^\\*$ 经 **UMAP 低维核**构造**老师图** $Q^\\*$；用 **GNN** 从分子图预测**学生图** $\\hat P$（两种核形式：固定 UMAP 同族核/行自适应核），以**交叉熵** $\\mathrm{CE}(Q^\\*, \\hat P)$ 进行监督训练。推理时，给定新分子，GNN 预测 $\\hat P$，再最小化 $\\mathrm{CE}(\\hat P, Q(Y))$ 获得 3D 坐标 $Y$。该框架天然刚体不变，具备“拉/推”双向信号，统一了摊销学习与非参数几何微调。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 背景与动机\n",
    "\n",
    "* 传统路线：\n",
    "\n",
    "  1. 等变 GNN/扩散直接回归/采样坐标；\n",
    "  2. 距离几何/能量最小化；\n",
    "  3. 统计嵌入 + 力场混合。\n",
    "* 我们的视角：**流形学习**。把 3D 几何表述为**概率图**，将“化学表征流形”与“欧氏 3D 流形”做**概率对齐**，以 $\\mathrm{CE}$ 为核心目标，稳定且可解释。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 老师图 $Q^\\*$：由真实坐标构建\n",
    "\n",
    "给定真实/参考坐标 $Y^\\*=\\{y_i^\\*\\in\\mathbb{R}^3\\}$，用 **UMAP 低维核**（与 `min_dist, spread` 对应的 $(a,b)$）定义\n",
    "\n",
    "$$\n",
    "Q^\\*_{ij} \\;=\\; \\frac{1}{1 + a\\,\\|y_i^\\*-y_j^\\*\\|^{2b}},\\qquad Q^\\*_{ii}=0.\n",
    "$$\n",
    "\n",
    "> 实践：将 $Q^\\*$ 裁剪到 $[\\varepsilon,1-\\varepsilon]$（如 $10^{-12}$），并在**构建数据集阶段离线缓存**。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 学生图 $\\hat P$：由 GNN 学习（两种核）\n",
    "\n",
    "### 3.1 路线 A（固定核，度量学习，推荐起步）\n",
    "\n",
    "GNN 输出节点嵌入 $z_i\\in\\mathbb{R}^p$，两两距离\n",
    "\n",
    "$$\n",
    "d_{ij}=\\|z_i - z_j\\|.\n",
    "$$\n",
    "\n",
    "用与 $Q^\\*$ **同族的 UMAP 低维核**得到\n",
    "\n",
    "$$\n",
    "\\hat P_{ij} \\;=\\; \\frac{1}{1 + a\\, d_{ij}^{2b}}, \\qquad \\hat P_{ii}=0.\n",
    "$$\n",
    "\n",
    "**优点**：核族一致，$\\mathrm{CE}$ 优化稳定；$\\hat P$ 可**解析反解**为距离矩阵，便于 MDS 初始化 $Y$。\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 路线 B（行自适应核 + Fuzzy Union，UMAP 高维风格）\n",
    "\n",
    "GNN 额外输出逐节点参数 $\\rho_i,\\sigma_i>0$，并在 $z$-空间计算 $d_{ij}$。推荐两种行核：\n",
    "\n",
    "* **指数行核**（UMAP 原始高维核）\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij} \\;=\\; \\exp\\!\\Big(-\\frac{\\max(0,\\,d_{ij}-\\rho_i)}{\\sigma_i}\\Big).\n",
    "$$\n",
    "\n",
    "* **UMAP 同族行核**（与低维核同形）\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij} \\;=\\; \\frac{1}{1 + a\\,\\Big(\\max\\!\\big(0,\\tfrac{d_{ij}-\\rho_i}{\\sigma_i}\\big)\\Big)^{2b}}.\n",
    "$$\n",
    "\n",
    "行对称化用 **fuzzy union**：\n",
    "\n",
    "$$\n",
    "\\hat P_{ij} \\;=\\; q^{(i)}_{ij} + q^{(j)}_{ji} - q^{(i)}_{ij}\\,q^{(j)}_{ji},\\qquad \\hat P_{ii}=0.\n",
    "$$\n",
    "\n",
    "**优点**：**密度自适应**，跨分子分布差异鲁棒；**缺点**：$\\hat P$ 不可直接解析反解为欧氏距离（推理用 CE 对 $Y$ 微调即可）。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 训练目标与正则\n",
    "\n",
    "**主目标（只在非对角上求和）：**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{main}}\n",
    "=\\frac{1}{|S|}\\sum_{(i,j)\\in S}\n",
    "\\Big[-\\,Q^\\*_{ij}\\log \\hat P_{ij} - (1-Q^\\*_{ij})\\log(1-\\hat P_{ij})\\Big],\n",
    "$$\n",
    "\n",
    "其中 $S=\\{(i,j)\\mid i\\neq j\\}$（可加 hop 掩码/负采样）。\n",
    "\n",
    "**建议正则：**\n",
    "\n",
    "* **Smooth-k 行强度（行自适应核时）**\n",
    "  令 $s_i=\\sum_j q^{(i)}_{ij}$，目标 $s_i\\approx \\log_2(k_i+1)$：\n",
    "\n",
    "  $$\n",
    "  \\mathcal{R}_{k}=\\sum_i\\big(s_i-\\log_2(k_i+1)\\big)^2.\n",
    "  $$\n",
    "* **温度/范数**：约束 $\\|z_i\\|$ 或 $\\hat P$ 的行熵，避免过稀疏/过稠密。\n",
    "* **掩码与采样**：在 hop$\\le K$ 上密集监督，同时对远程对进行随机负采样，控制复杂度。\n",
    "\n",
    "**总损失：**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}=\\mathcal{L}_{\\text{main}} \\;+\\; \\lambda_k\\,\\mathcal{R}_{k} \\;(+\\;\\text{其他正则}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 训练与数据缓存\n",
    "\n",
    "* **数据端**：小分子建议**离线缓存 $Q^\\*$**（或 $D^\\*$ 以便后续换核）；对角置 0，概率裁剪到 $(\\varepsilon,1-\\varepsilon)$。\n",
    "* **复杂度**：全对为 $O(N^2)$。对较大分子，使用 hop 掩码 + 负采样，近似 $O(NK)$。\n",
    "* **稳定性**：概率裁剪、忽略对角、梯度裁剪；行核在 $d\\le \\rho_i$ 时导数为 0；候选极少的行可冻结。\n",
    "\n",
    "---\n",
    "\n",
    "## 6. 推理与几何解码（$\\hat P \\Rightarrow Y$）\n",
    "\n",
    "**通用**（两条路线都适用）：\n",
    "\n",
    "1. **GNN 前向**得到 $\\hat P$；\n",
    "2. **非参数 CE 微调**：以 $\\hat P$ 为目标，最小化\n",
    "\n",
    "   $$\n",
    "   \\min_Y\\ \\mathrm{CE}(\\hat P, Q(Y)),\\quad\n",
    "   Q_{ij}(Y)=\\frac{1}{1+a\\,\\|y_i-y_j\\|^{2b}}.\n",
    "   $$\n",
    "\n",
    "   迭代 10–50 步即可收敛（刚体不变，数值稳）。\n",
    "\n",
    "**路线 A 可加速（固定核可反解）：**\n",
    "\n",
    "$$\n",
    "\\hat D_{ij}\\;=\\;\\left(\\frac{1/\\hat P_{ij}-1}{a}\\right)^{\\!\\frac{1}{2b}},\n",
    "$$\n",
    "\n",
    "用 $\\hat D$ 先做 **MDS/SMACOF** 得到初值 $Y_0$，再做少量 CE 微调到 $Y$。\n",
    "\n",
    "---\n",
    "\n",
    "## 7. 模型结构（建议）\n",
    "\n",
    "* **Encoder**：原子/键特征 $\\rightarrow$ 多层 GNN（GINE/MPNN/GraphTransformer）$\\rightarrow h_i$。\n",
    "* **Metric 头（路线 A）**：$z_i=\\mathrm{MLP}(h_i)$；按 UMAP 低维核算 $\\hat P$。\n",
    "* **Row-adaptive 头（路线 B）**：$\\rho_i=\\mathrm{softplus}(\\mathrm{MLP}(h_i))+\\epsilon,\\ \\sigma_i=\\mathrm{softplus}(\\mathrm{MLP}(h_i))+\\epsilon$；行核 + fuzzy union 得 $\\hat P$。\n",
    "* **可选多任务**：行强度/温度预测、hop 可信度等。\n",
    "\n",
    "---\n",
    "\n",
    "## 8. 评测与基线\n",
    "\n",
    "* **指标**：\n",
    "  RMSD（Kabsch 对齐）、键长/键角/1-4 距离误差、立体冲突计数、MMFF 能量（参考）、$\\mathrm{CE}(Q^\\*, Q(Y))$。\n",
    "* **基线**：\n",
    "  ETKDG(+优化)、距离几何/MDS-stress、等变扩散/EGNN 坐标回归、无核对齐的对比学习。\n",
    "* **消融**：\n",
    "  去掉 smooth-k、去掉 hop 掩码、核族切换（exp vs UMAP 同族）、仅正项 CE、仅局部监督等。\n",
    "\n",
    "---\n",
    "\n",
    "## 9. 创新点（可写入论文贡献）\n",
    "\n",
    "\n",
    "1. **目标空间创新**：主目标不是能量/坐标回归，而是**概率图 CE 对齐**（含推开项）。天然刚体不变、数值稳定，这和主流的 E(n)-GNN/扩散（坐标生成）是不同的范式。\n",
    "2. **统一监督/无监督**：同一 CE 框架下，teacher 可取 $Q^\\*(Y^\\*)$（监督）或表征图 $P$（无监督）。这在分子 3D 里很少见。\n",
    "3. **行自适应核 + fuzzy union** 与 **固定 UMAP 低维核**两条学生图：一个密度鲁棒、一个可解析反解（利于初始化），**工程上好用**。\n",
    "4. **摊销 + 非参数微调**：先用 GNN 预测 $\\hat P$，再少量步 CE 微调 $Y$。相比一次性重构 $Y$，**推理速度/稳健性**兼顾。\n",
    "5. **可辨识性切入点**：当 $a,b$ 固定、边覆盖足够、CE→0 时，得到的 $Y$ 与 $Y^\\*$ 等距同构（至多刚体/镜像），这提供了**理论抓手**（现有扩散/能量方法很少从概率图角度给出）。\n",
    "\n",
    "---\n",
    "\n",
    "## 10. 高影响力“杀手锏”实验（建议优先做）\n",
    "\n",
    "* **Teacher 噪声鲁棒**：对 $Y^\\*$ 加噪生成 $Q^\\*$（或只给局部对），看你方法的收敛与恢复能力。\n",
    "* **速度–质量曲线**：在相同 wall-clock 下，你的“摊销 $\\hat P$ + CE 微调”对比扩散/能量最小化。\n",
    "* **跨分子泛化**：训练分布外化学家族（含多环/芳杂环/卤素/高自由度侧链），报告稳定性。\n",
    "* **解析反解 + SMACOF 的加速收益**（route-A），以及 **不反解直接 CE 微调**（route-B）的对比。\n",
    "* **局部监督→全局几何**：只给 hop≤2 的 $Q^\\*$，看是否能重建全局（用刚性理论做讨论）。\n",
    "\n",
    "---\n",
    "\n",
    "## 11.题目/卖点示例\n",
    "\n",
    "* **“Probabilistic Manifold Alignment for Molecular Conformer Generation via UMAP Kernels”**\n",
    "  *Aligning Teacher–Student Probability Graphs with Cross-Entropy to Recover 3D Coordinates*\n",
    "* 关键词：**probability alignment**, **row-adaptive kernels**, **fuzzy union**, **amortized + nonparametric refinement**, **rigidity-consistent**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 12. 训练/推理伪代码（简要）\n",
    "\n",
    "```python\n",
    "# 构建老师图（离线）\n",
    "Q_star = umap_low_kernel(dist(Y_star), a, b)     # 对角置0，并裁剪到 (eps,1-eps)\n",
    "\n",
    "# 训练（逐图）\n",
    "for batch in loader:\n",
    "    z, (rho, sigma) = gnn(batch)                 # 视路线而定\n",
    "    if route_A:\n",
    "        P_hat = umap_low_kernel(dist(z), a, b)\n",
    "    else:  # route_B\n",
    "        q_row = row_kernel(dist(z), rho, sigma)  # exp 或 UMAP 同族\n",
    "        P_hat = fuzzy_union(q_row)\n",
    "    loss = CE(Q_star, P_hat, offdiag_mask) + λk*R_smoothk(q_row)\n",
    "    loss.backward(); optimizer.step()\n",
    "\n",
    "# 推理\n",
    "z, (rho, sigma) = gnn(mol)\n",
    "if route_A:\n",
    "    P_hat = umap_low_kernel(dist(z), a, b)\n",
    "    D_hat = ((1/P_hat - 1)/a).clamp_min(0)**(1/(2*b))\n",
    "    Y0 = MDS_3D(D_hat); Y = CE_refine(P_hat, Y0, a, b)\n",
    "else:\n",
    "    P_hat = fuzzy_union(row_kernel(dist(z), rho, sigma))\n",
    "    Y0 = random_or_spectral_init(mol)            # 任意轻量初始化\n",
    "    Y  = CE_refine(P_hat, Y0, a, b)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 12. 结论\n",
    "\n",
    "  \n",
    "本方法把分子构象生成从“坐标/能量空间”迁移到**概率图空间**，以 $\\mathrm{CE}(Q^\\*, \\hat P)$ 驱动的**概率流形对齐**既稳定又可解释。通过**固定核/行自适应核**两类学生图与 GNN 的深度耦合，以及“**摊销预测 $\\hat P$ + 非参数 CE 微调 $Y$**”的推理流程，我们在不牺牲刚体不变性的前提下，获得了与等变扩散、距离几何截然不同且互补的路线。\n",
    "\n",
    "* **新意**：足够（方法视角与目标空间不同于主流）\n",
    "* **工作量**：中偏大（要跑强基线、写明理论、工程细节）\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 附：符号与核\n",
    "\n",
    "* 低维核：\n",
    "\n",
    "$$\n",
    "Q_{ij}(Y)=\\frac{1}{1+a\\,\\|y_i-y_j\\|^{2b}}\n",
    "$$\n",
    "\n",
    "* 指数行核：\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij}=\\exp\\!\\Big(-\\frac{\\max(0,\\,d_{ij}-\\rho_i)}{\\sigma_i}\\Big)\n",
    "$$\n",
    "\n",
    "* UMAP 同族行核：\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij}=\\frac{1}{1+a\\,\\Big(\\max\\!\\big(0,\\tfrac{d_{ij}-\\rho_i}{\\sigma_i}\\big)\\Big)^{2b}}\n",
    "$$\n",
    "\n",
    "* Fuzzy union：\n",
    "\n",
    "$$\n",
    "P_{ij}=q^{(i)}_{ij}+q^{(j)}_{ji}-q^{(i)}_{ij}\\,q^{(j)}_{ji}\n",
    "$$\n",
    "\n",
    "* 交叉熵（数值稳定需裁剪 $\\hat p$ 到 $(\\varepsilon,1-\\varepsilon)$）：\n",
    "\n",
    "$$\n",
    "\\mathrm{CE}(p,\\hat p) = -\\,p\\log\\hat p - (1-p)\\log(1-\\hat p).\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e0bf5-58c7-425a-9998-d4b0218c0f2f",
   "metadata": {},
   "source": [
    "# 附录 A：梯度推导（CE，对 $Y$ 与 GNN 参数）\n",
    "\n",
    "## A.1 记号与目标\n",
    "\n",
    "* 老师图 $Q^\\*$（由真实 $Y^\\*$ 用 **UMAP 低维核**构造）：\n",
    "\n",
    "  $$\n",
    "  Q^\\*_{ij}=\\frac{1}{1+a\\,\\|y_i^\\*-y_j^\\*\\|^{2b}},\\quad Q^\\*_{ii}=0.\n",
    "  $$\n",
    "* 学生图 $\\hat P$：由 GNN 预测（见 A.3 与 A.4）。\n",
    "* 训练目标（监督）：\n",
    "\n",
    "  $$\n",
    "  \\mathcal L_{\\text{train}}\n",
    "  \\;=\\;\\frac{1}{|S|}\\sum_{(i,j)\\in S}\n",
    "  \\Big[-Q^\\*_{ij}\\log \\hat P_{ij}-(1-Q^\\*_{ij})\\log(1-\\hat P_{ij})\\Big],\n",
    "  $$\n",
    "\n",
    "  其中 $S=\\{(i,j)\\mid i\\neq j\\}$（可结合 hop 掩码/负采样）。\n",
    "* 推理微调（非参数几何解码）：给定 $\\hat P$，最小化\n",
    "\n",
    "  $$\n",
    "  \\mathcal L_{\\text{refine}}(Y)=\\mathrm{CE}\\big(\\hat P,\\;Q(Y)\\big),\\qquad\n",
    "  Q_{ij}(Y)=\\frac{1}{1+a\\,\\|y_i-y_j\\|^{2b}}.\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## A.2 低维核 $Q(Y)$ 对 $Y$ 的梯度（用于推理微调）\n",
    "\n",
    "令 $d_{ij}=\\|y_i-y_j\\|$。有\n",
    "\n",
    "$$\n",
    "Q_{ij}=\\frac{1}{1+a\\,d_{ij}^{2b}},\\qquad\n",
    "\\frac{\\partial Q_{ij}}{\\partial d_{ij}}\n",
    "=\n",
    "-\\frac{2ab\\,d_{ij}^{\\,2b-1}}{\\big(1+a\\,d_{ij}^{2b}\\big)^2}\n",
    "\\;=\\;-2ab\\,d_{ij}^{\\,2b-1}\\,Q_{ij}^{\\,2}.\n",
    "$$\n",
    "\n",
    "交叉熵对 $Q$ 的导数：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{CE}}{\\partial Q_{ij}}\n",
    "= -\\frac{P_{ij}}{Q_{ij}}+\\frac{1-P_{ij}}{1-Q_{ij}},\n",
    "$$\n",
    "\n",
    "这里 $P$ 是目标概率图（推理时 $P=\\hat P$）。\n",
    "\n",
    "链式对距离：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{CE}}{\\partial d_{ij}}\n",
    "=\\frac{\\partial \\mathrm{CE}}{\\partial Q_{ij}}\n",
    "\\cdot\n",
    "\\frac{\\partial Q_{ij}}{\\partial d_{ij}}.\n",
    "$$\n",
    "\n",
    "由 $\\partial d_{ij}/\\partial y_i=(y_i-y_j)/d_{ij}$，得到\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{CE}}{\\partial y_i}\n",
    "=\\sum_{j\\neq i}\n",
    "\\frac{\\partial \\mathrm{CE}}{\\partial d_{ij}}\n",
    "\\cdot\n",
    "\\frac{y_i-y_j}{d_{ij}}.\n",
    "$$\n",
    "\n",
    "> 实作要点：对角不参与；对 $Q$ 做 $\\mathrm{clip}\\in(10^{-12},1-10^{-12})$；对 $d$ 加 $\\varepsilon$ 防零除。\n",
    "\n",
    "---\n",
    "\n",
    "## A.3 路线 A：固定 UMAP 低维核，从 GNN 嵌入 $z$ 得 $\\hat P$\n",
    "\n",
    "令 $r_{ij}=\\|z_i-z_j\\|$，\n",
    "\n",
    "$$\n",
    "\\hat P_{ij}=\\frac{1}{1+a\\,r_{ij}^{2b}},\\qquad\n",
    "\\frac{\\partial \\hat P_{ij}}{\\partial r_{ij}}\n",
    "=-\\frac{2ab\\,r_{ij}^{\\,2b-1}}{(1+a\\,r_{ij}^{2b})^2}.\n",
    "$$\n",
    "\n",
    "有\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal L_{\\text{train}}}{\\partial \\hat P_{ij}}\n",
    "=-\\frac{Q^\\*_{ij}}{\\hat P_{ij}}+\\frac{1-Q^\\*_{ij}}{1-\\hat P_{ij}}.\n",
    "$$\n",
    "\n",
    "链式对 $r_{ij}$：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal L_{\\text{train}}}{\\partial r_{ij}}\n",
    "=\\frac{\\partial \\mathcal L_{\\text{train}}}{\\partial \\hat P_{ij}}\n",
    "\\cdot\n",
    "\\frac{\\partial \\hat P_{ij}}{\\partial r_{ij}}.\n",
    "$$\n",
    "\n",
    "又 $\\partial r_{ij}/\\partial z_i=(z_i-z_j)/r_{ij}$，于是\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal L_{\\text{train}}}{\\partial z_i}\n",
    "=\\sum_{j\\neq i}\n",
    "\\frac{\\partial \\mathcal L_{\\text{train}}}{\\partial r_{ij}}\n",
    "\\cdot \\frac{z_i-z_j}{r_{ij}}.\n",
    "$$\n",
    "\n",
    "（注意矩阵是对称的，实际实现用张量广播一次性求和会更简洁。）\n",
    "\n",
    "---\n",
    "\n",
    "## A.4 路线 B：行自适应核 + Fuzzy Union，从 $z,\\rho,\\sigma$ 得 $\\hat P$\n",
    "\n",
    "记 $d_{ij}=\\|z_i-z_j\\|$，$s_{ij}=\\max(0,\\,d_{ij}-\\rho_i)$。\n",
    "\n",
    "### B.1 指数行核\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij}=\\exp\\!\\Big(-\\frac{s_{ij}}{\\sigma_i}\\Big).\n",
    "$$\n",
    "\n",
    "当 $s_{ij}>0$ 时：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial q^{(i)}_{ij}}{\\partial d_{ij}}=-\\frac{q^{(i)}_{ij}}{\\sigma_i},\\quad\n",
    "\\frac{\\partial q^{(i)}_{ij}}{\\partial \\rho_i}=+\\frac{q^{(i)}_{ij}}{\\sigma_i},\\quad\n",
    "\\frac{\\partial q^{(i)}_{ij}}{\\partial \\sigma_i}=q^{(i)}_{ij}\\frac{s_{ij}}{\\sigma_i^2}.\n",
    "$$\n",
    "\n",
    "当 $s_{ij}\\le 0$ 时，上式为 0（取 ReLU 的 0 子梯度）。\n",
    "\n",
    "### B.2 UMAP 同族行核\n",
    "\n",
    "$$\n",
    "q^{(i)}_{ij}=\\frac{1}{1+a\\Big(\\frac{s_{ij}}{\\sigma_i}\\Big)^{2b}}\\quad(s_{ij}>0\\ \\text{时有效})\n",
    "$$\n",
    "\n",
    "令 $u_{ij}=\\frac{s_{ij}}{\\sigma_i}$。有\n",
    "\n",
    "$$\n",
    "\\frac{\\partial q^{(i)}_{ij}}{\\partial u_{ij}}\n",
    "=-\\frac{2ab\\,u_{ij}^{2b-1}}{(1+a\\,u_{ij}^{2b})^2}.\n",
    "$$\n",
    "\n",
    "链式：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial q}{\\partial d_{ij}}\n",
    "=\\frac{1}{\\sigma_i}\\frac{\\partial q}{\\partial u_{ij}},\\quad\n",
    "\\frac{\\partial q}{\\partial \\rho_i}\n",
    "=-\\frac{1}{\\sigma_i}\\frac{\\partial q}{\\partial u_{ij}},\\quad\n",
    "\\frac{\\partial q}{\\partial \\sigma_i}\n",
    "=\\frac{\\partial q}{\\partial u_{ij}}\\cdot\\frac{\\partial u}{\\partial \\sigma_i}\n",
    "=\\frac{\\partial q}{\\partial u_{ij}}\\cdot\\Big(-\\frac{s_{ij}}{\\sigma_i^2}\\Big).\n",
    "$$\n",
    "\n",
    "（当 $s_{ij}\\le 0$ 时全为 0。）\n",
    "\n",
    "### B.3 Fuzzy union 对称化\n",
    "\n",
    "$$\n",
    "\\hat P_{ij}=q^{(i)}_{ij}+q^{(j)}_{ji}-q^{(i)}_{ij}\\,q^{(j)}_{ji}.\n",
    "$$\n",
    "\n",
    "于是\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat P_{ij}}{\\partial q^{(i)}_{ij}}=1-q^{(j)}_{ji},\\qquad\n",
    "\\frac{\\partial \\hat P_{ij}}{\\partial q^{(j)}_{ji}}=1-q^{(i)}_{ij}.\n",
    "$$\n",
    "\n",
    "再乘上 $\\partial \\mathcal L/\\partial \\hat P_{ij}$，即可把梯度**分流**到两条行核支路上；继续链式到 $d_{ij}$、$\\rho_i,\\sigma_i$、以及 $z_i$（通过 $\\partial d/\\partial z$）。\n",
    "\n",
    "---\n",
    "\n",
    "# 附录 B：从 GNN 到 $P$ 的实现（公式 + 代码）\n",
    "\n",
    "## B.1 公式总览\n",
    "\n",
    "* **路线 A（固定核）**：\n",
    "\n",
    "  $$\n",
    "  z_i=\\mathrm{GNN}(G)_i,\\;\\;\n",
    "  r_{ij}=\\|z_i-z_j\\|,\\;\\;\n",
    "  \\hat P_{ij}=\\frac{1}{1+a\\,r_{ij}^{2b}}.\n",
    "  $$\n",
    "\n",
    "* **路线 B（行自适应核 + union）**：\n",
    "\n",
    "  $$\n",
    "  h_i=\\mathrm{GNN}(G)_i,\\;\\;\n",
    "  z_i=\\mathrm{MLP}_z(h_i),\\;\\;\n",
    "  \\rho_i=\\mathrm{softplus}(\\mathrm{MLP}_\\rho(h_i))+\\epsilon,\\;\\;\n",
    "  \\sigma_i=\\mathrm{softplus}(\\mathrm{MLP}_\\sigma(h_i))+\\epsilon,\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  d_{ij}=\\|z_i-z_j\\|,\\;\\; s_{ij}=\\max(0,\\,d_{ij}-\\rho_i),\\;\\;\n",
    "  q^{(i)}_{ij}=\n",
    "  \\begin{cases}\n",
    "  \\exp(-s_{ij}/\\sigma_i) & \\text{(exp)}\\\\[2pt]\n",
    "  \\dfrac{1}{1+a\\,(s_{ij}/\\sigma_i)^{2b}} & \\text{(UMAP 同族)}\n",
    "  \\end{cases}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\hat P_{ij}=q^{(i)}_{ij}+q^{(j)}_{ji}-q^{(i)}_{ij}\\,q^{(j)}_{ji}.\n",
    "  $$\n",
    "\n",
    "> 训练损失：$\\mathcal L=\\mathrm{CE}(Q^\\*,\\hat P)+\\lambda_k\\,\\mathcal R_{\\text{smooth-k}}(q)$（可选）。\n",
    "\n",
    "---\n",
    "\n",
    "## B.2 PyTorch 代码骨架（两条路线可切换）\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "def pairwise_dists(X, eps=EPS):           # X: [n,p]\n",
    "    diff = X.unsqueeze(1) - X.unsqueeze(0)\n",
    "    return torch.sqrt((diff*diff).sum(-1) + eps)\n",
    "\n",
    "def ce_loss_stable(P_star, P_hat, mask_offdiag):\n",
    "    q = torch.clamp(P_hat, 1e-12, 1-1e-12)\n",
    "    p = P_star[mask_offdiag]; q = q[mask_offdiag]\n",
    "    return -(p*torch.log(q) + (1-p)*torch.log(1-q)).mean()\n",
    "\n",
    "# ---------- 路线 A：固定 UMAP 低维核 ----------\n",
    "class UMAPLowKernel(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super().__init__(); self.a=a; self.b=b\n",
    "    def forward(self, D):                 # D: [n,n]\n",
    "        Q = 1.0 / (1.0 + self.a * torch.clamp(D, min=EPS).pow(2*self.b))\n",
    "        Q = torch.clamp(Q, 1e-12, 1-1e-12)\n",
    "        Q.fill_diagonal_(0.0)\n",
    "        return Q\n",
    "\n",
    "class QFixedKernelGNN(nn.Module):\n",
    "    def __init__(self, in_dim, edge_dim, hidden=128, layers=4, z_dim=32, a=1.6, b=0.8):\n",
    "        super().__init__()\n",
    "        self.kernel = UMAPLowKernel(a,b)\n",
    "        self.xemb = nn.Linear(in_dim, hidden)\n",
    "        self.eemb = nn.Linear(edge_dim, hidden)\n",
    "        self.convs = nn.ModuleList([\n",
    "            GINEConv(nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(),\n",
    "                                   nn.Linear(hidden,hidden)))\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "        self.proj = nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(),\n",
    "                                  nn.Linear(hidden,z_dim))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        h = self.xemb(x); e = self.eemb(edge_attr)\n",
    "        for conv in self.convs:\n",
    "            h = F.relu(h + conv(h, edge_index, e))\n",
    "        z = self.proj(h)                  # [N, zdim]\n",
    "        D = pairwise_dists(z)             # r_ij\n",
    "        P_hat = self.kernel(D)            # 1/(1+a r^{2b})\n",
    "        return P_hat, {\"z\":z, \"D\":D}\n",
    "\n",
    "# ---------- 路线 B：行自适应核 + fuzzy union ----------\n",
    "class RowAdaptiveHead(nn.Module):\n",
    "    def __init__(self, family='exp', a=1.6, b=0.8):\n",
    "        super().__init__(); self.family=family; self.a=a; self.b=b\n",
    "\n",
    "    def qi_exp(self, D, rho, sigma):\n",
    "        # q_i(d) = exp( - relu(d - rho_i) / sigma_i )\n",
    "        X = torch.relu(D - rho[:, None])\n",
    "        return torch.exp(- X / (sigma[:, None] + EPS))\n",
    "\n",
    "    def qi_umap(self, D, rho, sigma):\n",
    "        # q_i(d) = 1 / (1 + a * (relu((d-rho)/sigma))^{2b})\n",
    "        X = torch.relu(D - rho[:, None]) / (sigma[:, None] + EPS)\n",
    "        return 1.0 / (1.0 + self.a * torch.clamp(X, min=0).pow(2*self.b))\n",
    "\n",
    "    def forward(self, D, rho, sigma, cand_mask=None):\n",
    "        qi = self.qi_exp(D, rho, sigma) if self.family=='exp' else self.qi_umap(D, rho, sigma)\n",
    "        if cand_mask is not None:         # 非候选置零（可选）\n",
    "            qi = qi * cand_mask.float()\n",
    "        qj = qi.transpose(0,1)\n",
    "        P = qi + qj - qi * qj             # fuzzy union\n",
    "        P = torch.clamp(P, 1e-12, 1-1e-12)\n",
    "        P.fill_diagonal_(0.0)\n",
    "        return P, qi\n",
    "\n",
    "class QRowAdaptiveGNN(nn.Module):\n",
    "    def __init__(self, in_dim, edge_dim, hidden=128, layers=4, z_dim=32, family='exp', a=1.6, b=0.8):\n",
    "        super().__init__()\n",
    "        self.head = RowAdaptiveHead(family, a, b)\n",
    "        self.xemb = nn.Linear(in_dim, hidden)\n",
    "        self.eemb = nn.Linear(edge_dim, hidden)\n",
    "        self.convs = nn.ModuleList([\n",
    "            GINEConv(nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(),\n",
    "                                   nn.Linear(hidden,hidden)))\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "        self.proj = nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(),\n",
    "                                  nn.Linear(hidden,z_dim))\n",
    "        self.rho_head   = nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(), nn.Linear(hidden,1))\n",
    "        self.sigma_head = nn.Sequential(nn.Linear(hidden,hidden), nn.ReLU(), nn.Linear(hidden,1))\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, cand_mask=None):\n",
    "        h = self.xemb(x); e = self.eemb(edge_attr)\n",
    "        for conv in self.convs:\n",
    "            h = F.relu(h + conv(h, edge_index, e))\n",
    "        z = self.proj(h)                              # [N, zdim]\n",
    "        D = pairwise_dists(z)                         # [N, N]\n",
    "        rho   = self.rho_head(h).squeeze(-1)          # [N]\n",
    "        sigma = self.softplus(self.sigma_head(h).squeeze(-1)) + 1e-3\n",
    "        P_hat, qi = self.head(D, rho, sigma, cand_mask=cand_mask)\n",
    "        return P_hat, {\"z\":z, \"D\":D, \"rho\":rho, \"sigma\":sigma, \"qi\":qi}\n",
    "```\n",
    "\n",
    "**训练步骤（逐图求 CE）**：\n",
    "\n",
    "```python\n",
    "def train_one_batch(model, data, optimizer):\n",
    "    model.train()\n",
    "    P_hat, aux = model(data.x, data.edge_index, data.edge_attr,\n",
    "                       cand_mask=getattr(data, \"cand_mask\", None))\n",
    "    N = P_hat.size(0)\n",
    "    mask_off = ~torch.eye(N, dtype=torch.bool, device=P_hat.device)\n",
    "    loss = ce_loss_stable(data.Q_star, P_hat, mask_off)   # Q_star 为缓存老师图\n",
    "    # 可选 smooth-k 正则（行自适应时）\n",
    "    if \"qi\" in aux:\n",
    "        k_target = torch.full((N,), 6.0, device=P_hat.device)\n",
    "        s = aux[\"qi\"].sum(dim=1)                          # 行强度\n",
    "        loss = loss + 0.1 * F.mse_loss(s, torch.log2(k_target+1.0))\n",
    "    optimizer.zero_grad(); loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "    optimizer.step()\n",
    "    return float(loss.item())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## B.3 数值稳定建议（避免 NaN）\n",
    "\n",
    "* 概率裁剪：$\\hat P\\gets\\mathrm{clip}(\\hat P,10^{-12},1-10^{-12})$，对角置 0；\n",
    "* 距离：$d=\\sqrt{\\|x\\|^2+\\varepsilon}$，$\\varepsilon\\approx 10^{-12}$；\n",
    "* 行自适应核：$\\sigma=\\mathrm{softplus}(\\cdot)+10^{-3}$；当候选邻居数 $\\le 2$ 的行可**冻结为等权**；\n",
    "* 训练早期用**较小学习率**，必要时对 $\\hat P$ 做温度匹配（如对 logits 加温度）；\n",
    "* 大分子：用 hop 掩码 + 远程负采样（每节点采样 K 个 j）把 $O(N^2)$ 压到 $O(NK)$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e897be-2603-4197-8af1-1829ff5c9754",
   "metadata": {},
   "source": [
    "# 附录 C：从P到Y的wei实现（公式 + 代码）\n",
    "\n",
    "### 1) 推理微调：`refine_Y_from_P`\n",
    "\n",
    "```python\n",
    "# =========================\n",
    "#  CE(P_hat, Q(Y)) 的推理微调\n",
    "# =========================\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "def pairwise_dists_torch(X, eps=EPS):\n",
    "    \"\"\"X: [n,3] -> D: [n,n]\"\"\"\n",
    "    diff = X.unsqueeze(1) - X.unsqueeze(0)\n",
    "    return torch.sqrt((diff * diff).sum(-1) + eps)\n",
    "\n",
    "class UMAPLowKernel(nn.Module):\n",
    "    \"\"\"\n",
    "    低维核：Q_ij(Y) = 1 / (1 + a * d_ij^{2b})\n",
    "    \"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = float(a); self.b = float(b)\n",
    "\n",
    "    def forward(self, D):\n",
    "        Q = 1.0 / (1.0 + self.a * torch.clamp(D, min=EPS).pow(2.0 * self.b))\n",
    "        Q = torch.clamp(Q, 1e-12, 1 - 1e-12)\n",
    "        Q.fill_diagonal_(0.0)\n",
    "        return Q\n",
    "\n",
    "def ce_loss_offdiag(P_tgt, Q, mask_offdiag):\n",
    "    \"\"\"\n",
    "    稳定的 CE：只在 off-diagonal 上计算\n",
    "    \"\"\"\n",
    "    q = torch.clamp(Q, 1e-12, 1-1e-12)\n",
    "    p = torch.clamp(P_tgt, 1e-12, 1-1e-12)\n",
    "    return -(p[mask_offdiag] * torch.log(q[mask_offdiag]) +\n",
    "             (1 - p[mask_offdiag]) * torch.log(1 - q[mask_offdiag])).mean()\n",
    "\n",
    "def center_and_rescale_torch(Y, eps=1e-6):\n",
    "    with torch.no_grad():\n",
    "        Y -= Y.mean(dim=0, keepdim=True)\n",
    "        # 统一一个 RMS 尺度，避免数值漂移\n",
    "        rms = Y.pow(2).mean().sqrt()\n",
    "        Y /= (rms + eps)\n",
    "    return Y\n",
    "\n",
    "def refine_Y_from_P(P_hat, a, b, steps=50, lr=1e-2,\n",
    "                    Y0=None, init=\"random\", device=\"cpu\",\n",
    "                    grad_clip=5.0, verbose=False):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "      - P_hat: 目标概率图 (numpy 或 torch.float32 [n,n])\n",
    "      - (a, b): UMAP 低维核参数（和训练保持一致）\n",
    "      - steps, lr: 微调步数与学习率\n",
    "      - Y0: 可选初值（[n,3]），若为 None 则根据 init 初始化\n",
    "      - init: \"random\" / \"spectral\"（若你有谱初始化）/ 其它\n",
    "      - grad_clip: 梯度裁剪阈值\n",
    "    输出：\n",
    "      - Y: numpy 数组 [n,3]\n",
    "      - hist: 每步的 CE 损失列表\n",
    "    \"\"\"\n",
    "    # --- 准备数据\n",
    "    if isinstance(P_hat, np.ndarray):\n",
    "        P_tgt = torch.tensor(P_hat, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        P_tgt = P_hat.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    n = P_tgt.size(0)\n",
    "    eye = torch.eye(n, dtype=torch.bool, device=device)\n",
    "    mask_off = ~eye\n",
    "\n",
    "    # --- 初始化 Y\n",
    "    if Y0 is None:\n",
    "        if init == \"random\":\n",
    "            Y = torch.randn(n, 3, device=device) * 0.01\n",
    "        else:\n",
    "            # 兜底：随机\n",
    "            Y = torch.randn(n, 3, device=device) * 0.01\n",
    "    else:\n",
    "        if isinstance(Y0, np.ndarray):\n",
    "            Y = torch.tensor(Y0, dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            Y = Y0.to(device=device, dtype=torch.float32)\n",
    "    Y.requires_grad_(True)\n",
    "    center_and_rescale_torch(Y)\n",
    "\n",
    "    kernel = UMAPLowKernel(a, b).to(device)\n",
    "    opt = torch.optim.Adam([Y], lr=lr)\n",
    "    hist = []\n",
    "\n",
    "    for t in range(steps):\n",
    "        D = pairwise_dists_torch(Y)\n",
    "        Q = kernel(D)\n",
    "        loss = ce_loss_offdiag(P_tgt, Q, mask_off)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # 梯度裁剪（避免大步震荡）\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_([Y], grad_clip)\n",
    "        opt.step()\n",
    "        center_and_rescale_torch(Y)\n",
    "        val = float(loss.item())\n",
    "        hist.append(val)\n",
    "        if verbose and (t % 10 == 0 or t == steps - 1):\n",
    "            print(f\"[refine {t:03d}] CE={val:.6f}\")\n",
    "\n",
    "    return Y.detach().cpu().numpy(), hist\n",
    "```\n",
    "\n",
    "**使用示例（单分子）**：\n",
    "\n",
    "```python\n",
    "# 假设你已有 P_hat (numpy [n,n])，以及 UMAP 低维核参数 a,b\n",
    "Y_pred, hist = refine_Y_from_P(P_hat, a, b, steps=50, lr=1e-2, init=\"random\", device=\"cpu\", verbose=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2) SMACOF-3D 初始化（含解析反解）\n",
    "\n",
    "**场景**：当你的学生图来自“固定低维核（路线 A）”，$\\hat P=1/(1+a r^{2b})$ 可**解析反解**出距离矩阵 $\\hat D$，再用 MDS/SMACOF 得到一个更稳的初值 $Y_0$，最后喂给 `refine_Y_from_P` 微调十几步即可。\n",
    "\n",
    "```python\n",
    "# =========================\n",
    "#   解析反解 + MDS/SMACOF\n",
    "# =========================\n",
    "import numpy as np\n",
    "\n",
    "def invert_umap_q(P, a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    从固定 UMAP 低维核的概率 P 反解欧氏距离：\n",
    "    D_ij = ((1/P_ij - 1)/a)^(1/(2b))\n",
    "    注意：仅适用于“固定核路线”，行自适应核+fuzzy union不可直接反解。\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=np.float64)\n",
    "    P = np.clip(P, 1e-8, 1 - 1e-8)\n",
    "    X = (1.0 / P - 1.0) / float(a)\n",
    "    D = np.power(np.clip(X, 0.0, None), 1.0 / (2.0 * float(b)))\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def classical_mds_3d(D):\n",
    "    \"\"\"\n",
    "    经典 MDS（Torgerson）：Double-centering + 特征分解，取前 3 个正特征。\n",
    "    D: [n,n] 欧氏距离矩阵\n",
    "    \"\"\"\n",
    "    D2 = D ** 2\n",
    "    n = D.shape[0]\n",
    "    J = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * J @ D2 @ J\n",
    "    # 特征分解\n",
    "    w, V = np.linalg.eigh(B)\n",
    "    idx = np.argsort(w)[::-1]    # 降序\n",
    "    w = w[idx]\n",
    "    V = V[:, idx]\n",
    "    # 取前 3 个非负特征\n",
    "    pos = w[:3].clip(min=0.0)\n",
    "    L = np.diag(np.sqrt(pos + 1e-12))\n",
    "    X = V[:, :3] @ L\n",
    "    # 中心化（B 已经中心化，理论上均值为 0）\n",
    "    X -= X.mean(axis=0, keepdims=True)\n",
    "    # 归一化（稳定后续 CE）\n",
    "    X /= (np.sqrt((X**2).mean()) + 1e-6)\n",
    "    return X\n",
    "\n",
    "def smacof_3d(D, Y0=None, max_iter=200, tol=1e-6, verbose=False, random_state=0):\n",
    "    \"\"\"\n",
    "    轻量 SMACOF（等权）：最小化应力 sum_{i<j} (d_ij(X) - D_ij)^2\n",
    "    参考：Borg & Groenen, Modern Multidimensional Scaling\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = D.shape[0]\n",
    "    if Y0 is None:\n",
    "        X = rng.normal(scale=1e-2, size=(n, 3))\n",
    "    else:\n",
    "        X = np.array(Y0, dtype=np.float64)\n",
    "\n",
    "    D = np.asarray(D, dtype=np.float64)\n",
    "    W = np.ones_like(D) - np.eye(n)  # 等权重\n",
    "    eps = 1e-12\n",
    "\n",
    "    def stress(X):\n",
    "        diff = X[:, None, :] - X[None, :, :]\n",
    "        d = np.sqrt((diff**2).sum(-1) + eps)\n",
    "        return 0.5 * (W * (d - D)**2).sum()\n",
    "\n",
    "    prev = stress(X)\n",
    "    for it in range(max_iter):\n",
    "        # 计算 d(X) 与 B(X)\n",
    "        diff = X[:, None, :] - X[None, :, :]\n",
    "        d = np.sqrt((diff**2).sum(-1) + eps)\n",
    "        R = W * (D / d)\n",
    "        np.fill_diagonal(R, 0.0)\n",
    "        B = -R\n",
    "        B[np.diag_indices(n)] = -B.sum(axis=1)\n",
    "        # 更新（等权情形下约化成 (1/n) B X）\n",
    "        X = (1.0 / n) * (B @ X)\n",
    "        # 居中+归一\n",
    "        X -= X.mean(axis=0, keepdims=True)\n",
    "        X /= (np.sqrt((X**2).mean()) + 1e-6)\n",
    "\n",
    "        cur = stress(X)\n",
    "        if verbose and (it % 10 == 0 or it == max_iter - 1):\n",
    "            print(f\"[SMACOF {it:03d}] stress={cur:.6f}\")\n",
    "        if abs(prev - cur) < tol * (1.0 + prev):\n",
    "            break\n",
    "        prev = cur\n",
    "    return X\n",
    "```\n",
    "\n",
    "**route-A 的完整推理范式（$\\hat P \\Rightarrow Y$）**：\n",
    "\n",
    "```python\n",
    "# 1) 从固定核的 P_hat 解析反解距离\n",
    "D_hat = invert_umap_q(P_hat, a, b)\n",
    "\n",
    "# 2) 用 MDS/SMACOF 得到一个稳定的初值 Y0\n",
    "Y0_cmds = classical_mds_3d(D_hat)       # 或用 smacof_3d(D_hat)\n",
    "\n",
    "# 3) 再做 10~50 步 CE 微调（统一流程）\n",
    "Y, hist = refine_Y_from_P(P_hat, a, b, steps=30, lr=1e-2, Y0=Y0_cmds, device=\"cpu\", verbose=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29540b9-27a9-4587-a4ba-f08e2e944186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
